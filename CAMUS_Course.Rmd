---
title: "Learn SIR Models and Basic Fitting"
output: learnr::tutorial
runtime: shiny_prerendered
date: "2023-04-11"
---

```{r setup, include=FALSE}
library(learnr)
library(readr)
library(deSolve)
library(EpiEstim)
library(tidyverse)
library(lubridate)
knitr::opts_chunk$set(echo = TRUE)

data_file <- read.csv("https://raw.githubusercontent.com/apwez/IDD_course/883be8b44cd4ccfa9dbbc1317802d665d1b27db0/Maryland_COVID19Data_IncidentCases.csv")

data_file$Date <- mdy(data_file$Date)

  # creating separate data objects for Baltimore city and Frederick county
  # removing the leading 0s in each time series
  balt_city <- data_file %>%
               dplyr::select(Date, new_cases=Baltimore.City) %>%
               filter(Date >= as.Date("2020-03-17"))

  fred_cty <- data_file %>%
              dplyr::select(Date, new_cases=Frederick.County) %>%
              filter(Date >= as.Date("2020-03-22"))
  
  sir_function <- function(t, y, param){

  # redefining parameters from param vector
  beta = param["beta"]
  gamma = param["gamma"]
  
  # redefining states
  S = y["S"]; I = y["I"]; R = y["R"]
  
  # calculating system of eq for given param, states
  dS = -beta*S*I 
  dI = beta*S*I - gamma*I
  dR = gamma*I 
  
  # returning list of current system of eq for time t
  return(list(c(dS, dI, dR)))}
  
# run_sir_model takes inputs
#   beta: transmission parameter (rate of infectious contacts per unit time [per person if freq=FALSE])
#   gamma: recovery rate, in 1/time units
#   initial.state: named vector of initial S, I, R states (must be # individuals for density dependent)
#   max.time: number of time units for which to run model
#   freq.dependent: logical for whether to run density dependent (FALSE) or frequency dependent (TRUE) model
run_sir_model <- function (beta, gamma, initial.state, max.time, freq.dependent) {

    # if frequency dependent model, divide beta by N, so that
    # ds/dt = -beta*S*I/N
    # if density dependent model, divide by 1
    beta.divisor <- ifelse(freq.dependent == TRUE, 
                           initial.state["S"] + initial.state["I"] + initial.state["R"], 
                           1)
    
    # create param vector to pass to SIR system of equations
    param <- c(beta = beta/beta.divisor, gamma = gamma)
    
    # create time vector across which to run model
    # note by default the time step is 1 unit
    times <- seq(0, max.time, 1)
    
    # solve the SIR system of equations for given times, parameters, initial conditions
    sir.output <- deSolve::lsoda(initial.state, times, sir_function, param)
    
    # return the SIR output, matrix of time, S, I, R values
    return(as.data.frame(sir.output))
}
  
```

## Welcome
This is a tutorial to construct a basic SIR model, simulate from this model, and then estimate a parameter to re-run the model with those values. 

### 

## BASIC SIR model

One of the cores of infectious disease modeling is the compartmental (mechanistic) model where individiuals are susceptible, become infected (and infectious) and then recover. The classic SIR model. Here we will go through building an SIR model and explore XX 
 
Let $S$ be the number of susceptible individuals, $I$ be infectious individuals, and $R$ be recovered individuals. We assume that infection confers perfect immunity. 

\begin{align*}
&\frac{dS}{dt} = - \frac{\beta S I}{N} \\
&\frac{dI}{dt} = \frac{\beta S I}{N} - \gamma I \\
&\frac{dR}{dt} = \gamma I 
\end{align*}
 
Under frequency dependence, transmission does not change with population density. Under this formulation $R_0 = \frac{\beta}{\gamma}$; that is, $R_0$ is constant with population size. $\beta$ is the transmission coefficient, the rate at which infectious contacts are made per unit time in the population. $\gamma$ is the recovery rate, such that $\frac{1}{\gamma}$ is the average duration of infection. This models assumes mass action and equal transmission and recovery rates in all members of the population.

```{r gen_time, echo = FALSE}
question("The average duration of infection for a particular disease is 5 days. This means:",
         answer("a) 20% recovers each day", message = 'there is another response that is also correct'),
         answer("b) in a population of 1000, 20 recover each day", message = 'this would be 200 if all 1000 were infected'),
         answer('c) for a second pathogen with the same beta, but gamma equaled 8 days, it would infect more people', message = 'there is another response that is also correct'),
         answer("a and b", message = 'this is wrong'), 
         answer('a and c', correct = TRUE),
         answer('b and c', message = 'this is wrong'),
         allow_retry = TRUE
         
)
```

###

## Code to construct a SIR model 

We can run code to construct this model as a series of differential equations: 

```{r sir}
# this function produces the SIR system of equations
# at time `t`, for states `y`, and parameters `param`
sir_function <- function(t, y, param){

  # redefining parameters from param vector
  beta = param["beta"]
  gamma = param["gamma"]
  
  # redefining states
  S = y["S"]; I = y["I"]; R = y["R"]
  
  # calculating system of eq for given param, states
  dS = -beta*S*I 
  dI = beta*S*I - gamma*I
  dR = gamma*I 
  
  # returning list of current system of eq for time t
  return(list(c(dS, dI, dR)))}

```

```{r betaSI, echo = FALSE}
question("Why does do we multiple beta times S and I?",
         answer("because we need to reduce the number of susceptible individuals in this equation", message = 'the beta times S and I is about transmission' ),
         answer("because the number who will get infected is impacted by the number who are susceptible", correct = TRUE),
         answer("because otherwise we would infect too many individuals", message = 'without taking into account the susceptible, we do not actually know how many individuals will get infected'),
         allow_retry = TRUE
)
```

### 
### Solving these equations

We will introduce R code to numerically integrate SIR models. First you will need to load a package called "deSolve". If you have not already installed this package in the past, you will have an error, so make sure you install it before running the following code. To install the package you can use 'require(deSolve)' or install it from the Packages tab. 

```{r solve_sir}

# run_sir_model takes inputs
#   beta: transmission parameter (rate of infectious contacts per unit time [per person if freq=FALSE])
#   gamma: recovery rate, in 1/time units
#   initial.state: named vector of initial S, I, R states (must be # individuals for density dependent)
#   max.time: number of time units for which to run model
#   freq.dependent: logical for whether to run density dependent (FALSE) or frequency dependent (TRUE) model
run_sir_model <- function (beta, gamma, initial.state, max.time, freq.dependent) {

    # if frequency dependent model, divide beta by N, so that
    # ds/dt = -beta*S*I/N
    # if density dependent model, divide by 1
    beta.divisor <- ifelse(freq.dependent == TRUE, 
                           initial.state["S"] + initial.state["I"] + initial.state["R"], 
                           1)
    
    # create param vector to pass to SIR system of equations
    param <- c(beta = beta/beta.divisor, gamma = gamma)
    
    # create time vector across which to run model
    # note by default the time step is 1 unit
    times <- seq(0, max.time, 1)
    
    # solve the SIR system of equations for given times, parameters, initial conditions
    sir.output <- deSolve::lsoda(initial.state, times, sir_function, param)
    
    # return the SIR output, matrix of time, S, I, R values
    return(as.data.frame(sir.output))
}

```


```{r measles, echo = FALSE}
question("For measles, what would the beta value be (assume R0 = 12) and the duration of infection is 14 days",
         answer('0.86', correct = TRUE),
         answer('168'),
         allow_retry = TRUE
)
```

###
## Running simulations with our model

Now we can run some simulations of our model. Here we have an example:

We can look at the model output using 'head()' and plot the output. Note we using `NA` in the first `plot` statement to return a blank plot, which we then populate using `lines`. You'll need to change the code below (pick the colors you'd like and plot I and R). 

```{r test_plot, exercise = TRUE, exercise.eval = FALSE}
test_output <- run_sir_model(beta = 1, gamma = 0.05,  initial.state = c(S = 500000, I = 1, R = 10000), max.time = 365, freq.dependent = TRUE)
head(test_output)

N = test_output$S[1] + test_output$I[1] + test_output$R[1] ## total population size
plot(NA, NA, xlim = c(min(test_output$time), max(test_output$time)), ylim = c(0,N), xlab = 'time', ylab = 'Proportion')
lines(test_output$time, test_output$S, col = 'blue', lty = 1)
legend('topright', legend = c('S'), col = c('blue'), pch = 16)
```


```{r r0, echo = FALSE}
question("What is R0 for our model above?",
         answer('20', correct = TRUE),
         answer('0.5'),
         allow_retry = TRUE
)
```

Now you can try it yourself. Run two more simulations labeled: test_output_high_beta (beta = 2) and test_output_low_beta (beta = 0.5) using the different beta values listed. All other parameters and states should be the same as above. Plot the output from these simulations on the same plot (lty = 2, for test_output_high_beta); (lty = 3, for test_output_low_beta). Make sure you are using appropriate axis limits. You may want to truncate the axis (try using `xlim`) for better visualization. You'll need to change the code below. 


```{r two_betas,  exercise = TRUE, exercise.eval = FALSE}
test_output <- run_sir_model(beta = 1, gamma = 0.05,  initial.state = c(S = 500000, I = 1, R = 10000), max.time = 365, freq.dependent = TRUE)
# high beta SIR
test_output_high_beta <- run_sir_model(beta = 1, gamma = 1,  initial.state = c(S = 500000, I = 1, R = 10000), max.time = 365, freq.dependent = TRUE)

# low beta SIR
test_output_low_beta <- run_sir_model(beta = 1, gamma = 1,  initial.state = c(S = 500000, I = 1, R = 10000), max.time = 365, freq.dependent = TRUE)

N = test_output$S[1] + test_output$I[1] + test_output$R[1] ## total population size

plot(NA, NA, xlim = c(min(test_output$time), 100), ylim = c(0,N), xlab = 'time', ylab = 'Proportion')
# plotting original beta
lines(test_output$time, test_output$S, col = 'blue', lty = 1)
lines(test_output$time, test_output$I, col = 'red', lty = 1, lwd=2)
lines(test_output$time, test_output$R, col = 'orange', lty = 1)
# plotting high beta

# plotting low beta

# adding legend

```


How these two epidemics differ. Why would a different beta value result in a different epidemic?

Answer = These models were all run under frequency dependent assumptions, so we would not expect differences due to changes in population size. Under frequency dependence, beta is the transmission coefficient, dictating the rate at which infectious contacts are made per unit time in the entire population. If beta increases, all else equal, the pathogen will be more transmissible because of this higher rate of potentially infectious contacts, and a larger outbreak will occur.

###

## Adding in an intervention 
Suppose there is a pathogen whose transmission can be approximated with an SIR model where beta = 3, gamma = 1/5. There is a new intervention in place that would reduce the transmissibility of the pathogen by half. Run two simulations (and plot the results) - one with the intervention and one without. What are the main differences between these two scenarios?  Justify which parameters and/or compartments you changed and why.   

We can use the same model structure, that is an SIR model with frequency dependence (note, you could also use a density dependent model, though $R_0$ would be much higher depending on the population size chosen; be sure to use the same population size across simulations for either assumption). 

When the intervention is in place, we let $\beta_{int} = \frac{\beta}{2} = 1.5$. Reducing the transmission coefficient by half is equivalent to reducing transmissibility by half. Note I'm truncating the time axis to 100 days for better visualization. You'll need to change the code below. 


```{r intervention, exercise = TRUE, exercise.eval = FALSE}

# no intervention model
out_no_int <- run_sir_model(beta = 3, gamma = 1/5,  initial.state = c(S = 500000, I = 1, R = 10000),  max.time = 365, freq.dependent = TRUE)

# low beta SIR
out_int <-  run_sir_model(beta = 3, gamma = 1/5,  initial.state = c(S = 500000, I = 1, R = 10000),  max.time = 365, freq.dependent = TRUE)

N = out_no_int$S[1] + out_no_int$I[1] + out_no_int$R[1] ## total population size

plot(NA, NA, xlim = c(0, 100), ylim = c(0,N), xlab = 'time', ylab = 'Proportion')
# plotting no intervention

# plotting intervention

# adding legend
legend('topright', legend = c('S', 'I', 'R', "intervention"), 
       col = c('blue', 'red', 'orange', 'black'), 
       lty=c(1,1,1,2), lwd=2)


```

###

## Other stuff

How much would I have to reduce transmission to avoid an outbreak altogether? Remember that no outbreak will occur if $R_0 < 1$. Here, $R_0 = \frac{3}{0.2} = 15$ with no intervention. To get $R_0$ below 1, I need $\frac{\beta_{int}}{0.2} \leq 1\ \Rightarrow \beta_{int} \leq 0.2$. Therefore, I have to reduce $\beta$ by over 90\% (from 3 to 0.2) to avoid an outbreak.

Let's look at outbreaks with 90\% and 95\% reductions in transmission. We'll just plot the I compartment for simplicity. You'll need to change the code below. 

```{r below1, exercise = TRUE, exercise.eval = FALSE}

# no intervention model
# no intervention model
out_no_int <- run_sir_model(beta = 3, gamma = 1/5,  initial.state = c(S = 500000, I = 1, R = 10000),  max.time = 365, freq.dependent = TRUE)

out90 <- run_sir_model(beta = 3*(1-1), gamma = 1/5,  initial.state = c(S = 500000, I = 1, R = 10000), max.time = 365, freq.dependent = TRUE)

out95 <- run_sir_model(beta = 3*(1-1), gamma = 1/5,  initial.state = c(S = 500000, I = 1, R = 10000), 
                       max.time = 365, freq.dependent = TRUE)

N = out90$S[1] + out90$I[1] + out90$R[1] ## total population size

plot(NA, NA, xlim = c(min(out_no_int$time), max(out_no_int$time)), ylim = c(0,N), xlab = 'time', ylab = 'Proportion')
# plotting no intervention
# plotting 90% intervention
# plotting 95% intervention
# adding legend

```



###

## Estimating Rt

========================================================
In this exercise, we will use the method of Cori et al., available in the `EpiEstim` package, to estimate the instantaneous reproductive number $R_t$ from publicly-available COVID-19 data. 

Load and plot the provided data from Maryland. Specifically, make one plot for the number of reported cases by day in Baltimore City and one plot for the reported cases in Frederick county. Describe generally in which time periods it appears $R_t>1$ for each county [1-2 sentences]. Are there any data points which seem anomalous, and what might these do to your estimates? (We won't cover methods for removing/resolving these anomalies - just discuss what their impact might be.)

You do not need to change the code below, but feel free to explore other locations too! 

```{r reading_in_data, eval = TRUE}
  # make sure you have saved the CSV on your computer
  # you may need to change your working directory and/or specify the full path to the data file

data_file <- read.csv("https://raw.githubusercontent.com/apwez/IDD_course/883be8b44cd4ccfa9dbbc1317802d665d1b27db0/Maryland_COVID19Data_IncidentCases.csv")

data_file$Date <- mdy(data_file$Date)

  # creating separate data objects for Baltimore city and Frederick county
  # removing the leading 0s in each time series
  balt_city <- data_file %>%
               dplyr::select(Date, new_cases=Baltimore.City) %>%
               filter(Date >= as.Date("2020-03-17"))

  fred_cty <- data_file %>%
              dplyr::select(Date, new_cases=Frederick.County) %>%
              filter(Date >= as.Date("2020-03-22"))
  
  ## plotting epi curves for each
  ggplot() +
    geom_line(data=balt_city, aes(x=Date, y=new_cases), color="darkred") +
    geom_line(data=fred_cty, aes(x=Date, y=new_cases), color="navyblue") +
    scale_x_date(name="", breaks="2 weeks") +
    theme_bw() +
    theme(axis.text.x = element_text(angle=45, hjust=1, vjust=1))

```

Now we can use the following code to estimate $R_t$ for Baltimore City, and repeat the process for Frederick County. Plot the estimates for each with their 95\% CI (hint: try `geom_ribbon` if using ggplot, or `polygon` if using base R). Make sure to include a legend, labels, etc for your figure. Compare estimates from the two counties and how these align with the incidence data you plotted above. Edit the code to add a location of your choice for the same procedure! 

```{r rt_est, exercise = TRUE, exercise.eval = FALSE, fig.width=6, fig.height=4}

  # defining time windows (1 week) for smoothing estimation
  t_start = seq(2, nrow(balt_city)-7)
  t_end = t_start + 7
  
  # estimating for baltimore, using 7 day windows + 4d serial interval
  balt_rt <- estimate_R(balt_city$new_cases, 
                        method = 'parametric_si', 
                        config = make_config(list(mean_si = 4, std_si = 4.75, t_start=t_start, t_end=t_end))) 

  # summarizing Rt results
  balt_df <- data.frame(date_start = balt_city$Date[t_start],
                        est = balt_rt$R$`Mean(R)`,
                        lower_ci = balt_rt$R$`Quantile.0.025(R)`,
                        upper_ci=balt_rt$R$`Quantile.0.975(R)`) %>%
             mutate(date = date_start + 3)
  
  # defining time windows (1 week) for smoothing estimation
  t_start = seq(2, nrow(fred_cty)-7)
  t_end = t_start + 7
  
  # estimating for Frederick county, using 7 day windows + 4d serial interval
  fred_rt <- estimate_R(fred_cty$new_cases, 
                        method = 'parametric_si', 
                        config = make_config(list(mean_si = 4, std_si = 4.75, t_start=t_start, t_end=t_end))) 

  # summarizing Rt results
  fred_df <- data.frame(date_start = fred_cty$Date[t_start],
                        est = fred_rt$R$`Mean(R)`,
                        lower_ci = fred_rt$R$`Quantile.0.025(R)`,
                        upper_ci=fred_rt$R$`Quantile.0.975(R)`) %>%
             mutate(date = date_start + 3)
  
  # combining data from each county for plotting
  plt_df <- balt_df %>%
            mutate(county="Baltimore city") %>%
            bind_rows(fred_df %>% mutate(county="Frederick county"))
  
  # plotting Rt for both counties
  p1<- ggplot(plt_df, aes(x=date, y=est, ymin=lower_ci, ymax=upper_ci, color=county, fill=county)) +
        geom_line() +
        geom_ribbon(alpha=0.2, color=NA) +
        geom_hline(yintercept = 1, linetype="dashed") +
        theme_bw() +
        theme(legend.position = "bottom")
  p1
  
```


We used an estimate of the serial interval above from an early paper [investigating cases in China before February 8, 2020](https://wwwnc.cdc.gov/eid/article/26/6/20-0357_article). This paper found a mean serial interval of 4 days, with a standard deviation of 4.75 days. Suppose you had data (e.g., like [this paper investigating cases in Lombardy, Italy](https://arxiv.org/pdf/2003.09320.pdf)) which indicates the mean serial interval is closer to 7 days. Assuming the same standard deviation (4.75 days), repeat the estimation process above for both locations. Create 1-2 plots to compare the two estimates from each county and discuss the differences [1-2 sentences].

```{r longer_si, fig.width=6, fig.height=6, exercise = TRUE, exercise.eval = FALSE}

  # defining time windows (1 week) for smoothing estimation
  t_start = seq(2, nrow(balt_city)-7)
  t_end = t_start + 7

  # estimating for Baltimre, using 7 day windows + 7d serial interval
  balt_rt_longsi <- estimate_R(balt_city$new_cases, 
                        method = 'parametric_si', 
                        config = make_config(list(mean_si = 1, std_si = 1, t_start=t_start, t_end=t_end))) 

  balt_df_longsi <- data.frame(date_start = balt_city$Date[t_start],
                               est = balt_rt_longsi$R$`Mean(R)`,
                               lower_ci = balt_rt_longsi$R$`Quantile.0.025(R)`,
                               upper_ci=balt_rt_longsi$R$`Quantile.0.975(R)`) %>%
                    mutate(date = date_start + 3)
  

  # defining time windows (1 week) for smoothing estimation
  t_start = seq(2, nrow(fred_cty)-7)
  t_end = t_start + 7
  fred_rt_longsi <- estimate_R(fred_cty$new_cases, 
                          method = 'parametric_si', 
                          config = make_config(list(mean_si = 1, std_si = 1, t_start=t_start, t_end=t_end))) 

  # estimating for Frederick, using 7 day windows + 7d serial interval
  fred_df_longsi <- data.frame(date_start = fred_cty$Date[t_start],
                               est = fred_rt_longsi$R$`Mean(R)`,
                               lower_ci = fred_rt_longsi$R$`Quantile.0.025(R)`,
                               upper_ci=fred_rt_longsi$R$`Quantile.0.975(R)`) %>%
                    mutate(date = date_start + 3)
  
  # combining data from each county for plotting
  plt_df_longsi <- balt_df_longsi %>%
                   mutate(county="Baltimore city") %>%
                   bind_rows(fred_df_longsi %>% mutate(county="Frederick county"))
  
  # plotting Rt for both counties w 4d estimate
  p2 <- ggplot(plt_df_longsi, aes(x=date, y=est, ymin=lower_ci, ymax=upper_ci, color=county, fill=county)) +
          geom_line() +
          geom_ribbon(alpha=0.2, color=NA) +
          geom_hline(yintercept = 1, linetype="dashed") +
          theme_bw() +
          theme(legend.position = "bottom") 

  cowplot::plot_grid(p1 + lims(y=c(0.4, 5.6)), p2 + lims(y=c(0.4, 5.6)), nrow=2, labels=c("SI=4d", "SI=7d"))
  
    # combining 4 + 7 day serial interval estimates
  plt_comb <- plt_df_longsi %>%
              rename(est_long = est,
                     lower_ci_long = lower_ci,
                     upper_ci_long = upper_ci) %>%
              full_join(plt_df)

  # creating scatterplots of 4d vs 7d serial interval estimates
  p_est = ggplot(plt_comb) +
        geom_point(aes(x=est, y=est_long), color="#7570B3", alpha=0.2) +
        geom_abline(slope=1, intercept=0) +
        labs(title="mean Rt", x="estimate (serial interval=4 days)", y="estimate (serial interval=7 days)") +
        lims(x=c(0.5, 3), y=c(0.4, 5.6)) +
        theme_bw()
 
  p_lci = ggplot(plt_comb) +
        geom_point(aes(x=lower_ci, y=lower_ci_long), color="#58d6a4", alpha=0.2) +
        geom_abline(slope=1, intercept=0) +
        labs(title="lower CI", x="estimate (serial interval=4 days)", y="estimate (serial interval=7 days)") +
        lims(x=c(0.5, 3), y=c(0.4, 5.6)) +
        theme_bw()
    
  p_uci = ggplot(plt_comb) +
        geom_point(aes(x=upper_ci, y=upper_ci_long), color="#58aed6", alpha=0.2) +
        geom_abline(slope=1, intercept=0) +
        labs(title="upper CI", x="estimate (serial interval=4 days)", y="estimate (serial interval=7 days)") +
        lims(x=c(0.5, 3), y=c(0.4, 5.6)) +
        theme_bw()
  
  cowplot::plot_grid(p_lci, p_est, p_uci, nrow=1)
  
```

